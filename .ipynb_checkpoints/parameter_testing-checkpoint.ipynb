{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import warnings\n",
    "\n",
    "import time as time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from matplotlib import transforms\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Read out 100 rows rather than the default value. \n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Not prinitng the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting the working path for data input and result outputs\n",
    "os.chdir('D:\\\\Spring 2019\\\\DS 440\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: \n",
      "(45377, 26)\n"
     ]
    }
   ],
   "source": [
    "#filenames = glob('D:\\Spring 2019\\DS 440\\Data\\kplr_dr25_inj*.csv')\n",
    "#df = pd.concat([pd.read_csv(f) for f in filenames], ignore_index = True)\n",
    "\n",
    "# Problem 2\n",
    "#df = pd.read_csv('kplr_dr25_inj1_plti.csv', header = 0)\n",
    "\n",
    "# Problem 2\n",
    "df = pd.read_csv('kplr_dr25_inj1_tces.csv', header = 0)\n",
    "\n",
    "print('Size: ')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntemp_df = df.iloc[:, 0:15]\\ndf_drop = temp_df[temp_df.isnull().any(axis=1)]\\ntemp_df = temp_df.drop(df_drop.index.values)\\nprint(temp_df.shape)\\n\\nX = temp_df.iloc[:, 1:14]\\nY = temp_df.iloc[:, 14]\\ncols_indices = X.columns\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df.iloc[:, 0:15]\n",
    "df_drop = temp_df[temp_df.isnull().any(axis=1)]\n",
    "temp_df = temp_df.drop(df_drop.index.values)\n",
    "print(temp_df.shape)\n",
    "\n",
    "X = temp_df.iloc[:, 1:14]\n",
    "Y = temp_df.iloc[:, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df['Disp'] = df['Disp'].replace('PC', 1)\n",
    "df['Disp'] = df['Disp'].replace('FP', 0)\n",
    "\n",
    "X = df.iloc[:,10:25]\n",
    "Y = df.iloc[:,2]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 350, num = 5)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 10)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Minimum number of neighbors required for each node\n",
    "n_neighbors = [int(x) for x in np.linspace(start = 3, stop = 30, num = 10)]\n",
    "\n",
    "# Minimum Power parameter required for the Minkowski metric\n",
    "p = [float(x) for x in np.linspace(start = 1, stop = 5, num = 10)]\n",
    "\n",
    "knc = KNeighborsClassifier() #n_neighbors, p\n",
    "abc = AdaBoostClassifier() #n_estimators\n",
    "xgb = XGBClassifier() #n_estimators, max_depth\n",
    "dtc = DecisionTreeClassifier() #max_depth, min_samples_split, min_samples_leaf\n",
    "etc = ExtraTreesClassifier() #n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "rfc = RandomForestClassifier() #n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "gbc = GradientBoostingClassifier() #n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the param grid\n",
    "param_grid = dict(n_neighbors = n_neighbors,\n",
    "                  p = p)\n",
    "\n",
    "print('KNeighbors Classifier')\n",
    "knc_grid_search = GridSearchCV(knc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "knc_grid_result = knc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = n_estimators)\n",
    "\n",
    "print('AdaBoost Classifier')\n",
    "abc_grid_search = GridSearchCV(abc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "abc_grid_result = abc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = n_estimators,\n",
    "                  max_depth = max_depth)\n",
    "\n",
    "print('XGBoost Classifier')\n",
    "xgb_grid_search = GridSearchCV(xgb, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "xgb_grid_result = xgb_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(max_depth = max_depth,\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "print('DecisionTree Classifier')\n",
    "dtc_grid_search = GridSearchCV(dtc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "dtc_grid_result = dtc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = n_estimators,\n",
    "                  max_depth = max_depth,\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "print('ExtraTrees Classifier')\n",
    "etc_grid_search = GridSearchCV(etc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "etc_grid_result = etc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "print('RandomForest Classifier')\n",
    "rfc_grid_search = GridSearchCV(rfc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "rfc_grid_result = rfc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "#print('GradientBoosting Classifier')\n",
    "#gbc_grid_search = GridSearchCV(gbc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "#gbc_grid_result = gbc_grid_search.fit(X, Y)\n",
    "\n",
    "#dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Classifier:\n",
      "Best: 0.852767 using {'n_neighbors': 27, 'p': 1.0}\n",
      "\n",
      "AdaBoost Classifier:\n",
      "Best: 0.862155 using {'n_estimators': 180}\n",
      "\n",
      "XGBoost Classifier:\n",
      "Best: 0.865945 using {'max_depth': 5, 'n_estimators': 265}\n",
      "\n",
      "DecisionTree Classifier:\n",
      "Best: 0.859025 using {'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\n",
      "ExtraTrees Classifier:\n",
      "Best: 0.863764 using {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 265}\n",
      "\n",
      "RandomForest Classifier:\n",
      "Best: 0.866122 using {'max_depth': 23, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 265}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results\n",
    "print('KNeighbors Classifier:')\n",
    "print(\"Best: %f using %s\" % (knc_grid_result.best_score_, knc_grid_result.best_params_))\n",
    "\n",
    "print('\\nAdaBoost Classifier:')\n",
    "print(\"Best: %f using %s\" % (abc_grid_result.best_score_, abc_grid_result.best_params_))\n",
    "\n",
    "print('\\nXGBoost Classifier:')\n",
    "print(\"Best: %f using %s\" % (xgb_grid_result.best_score_, xgb_grid_result.best_params_))\n",
    "\n",
    "print('\\nDecisionTree Classifier:')\n",
    "print(\"Best: %f using %s\" % (dtc_grid_result.best_score_, dtc_grid_result.best_params_))\n",
    "\n",
    "print('\\nExtraTrees Classifier:')\n",
    "print(\"Best: %f using %s\" % (etc_grid_result.best_score_, etc_grid_result.best_params_))\n",
    "\n",
    "print('\\nRandomForest Classifier:')\n",
    "print(\"Best: %f using %s\" % (rfc_grid_result.best_score_, rfc_grid_result.best_params_))\n",
    "\n",
    "#print('\\nGradientBoosting Classifier:')\n",
    "#print(\"Best: %f using %s\" % (gbc_grid_result.best_score_, gbc_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmeans = _grid_result.cv_results_[\\'mean_test_score\\']\\nstds = _grid_result.cv_results_[\\'std_test_score\\']\\nparams = _grid_result.cv_results_[\\'params\\']\\nfor mean, stdev, param in zip(means, stds, params):\\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "means = _grid_result.cv_results_['mean_test_score']\n",
    "stds = _grid_result.cv_results_['std_test_score']\n",
    "params = _grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
