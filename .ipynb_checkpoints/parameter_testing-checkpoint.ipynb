{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Read out 100 rows rather than the default value. \n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Not prinitng the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting the working path for data input and result outputs\n",
    "os.chdir('D:\\\\Spring 2019\\\\DS 440\\\\Data')\n",
    "\n",
    "# Setting a random seed for reproducability\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "(146294, 25)\n",
      "\n",
      "Cleaned Dataset Size:\n",
      "(145671, 15)\n",
      "\n",
      "Input Size: (145671, 13)\n",
      "Output Size: (145671,)\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "df = pd.read_csv('kplr_dr25_inj1_plti.csv', header = 0)\n",
    "\n",
    "#filenames = glob('D:\\Spring 2019\\DS 440\\Data\\kplr_dr25_inj*.csv')\n",
    "#df = pd.concat([pd.read_csv(f) for f in filenames], ignore_index = True)\n",
    "\n",
    "print('Dataset Size:')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "temp_df = df.iloc[:, 0:15]\n",
    "df_drop = temp_df[temp_df.isnull().any(axis=1)]\n",
    "temp_df = temp_df.drop(df_drop.index.values)\n",
    "temp_df = temp_df[temp_df.Recovered != 2]\n",
    "\n",
    "print('Cleaned Dataset Size:')\n",
    "print(temp_df.shape)\n",
    "print()\n",
    "\n",
    "X = temp_df.iloc[:, 1:14]\n",
    "Y = temp_df.iloc[:, 14]\n",
    "\n",
    "print('Input Size:', X.shape)\n",
    "print('Output Size:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Problem 2\\ndf = pd.read_csv('kplr_dr25_inj1_tces.csv', header = 0)\\n\\nprint('Dataset Size: ')\\nprint(df.shape)\\nprint()\\n\\ncols = ['TCE_ID', 'KIC', 'Disp', 'Score', 'period', 'epoch', 'NTL', 'SS', \\n        'CO', 'EM', 'Expected_MES', 'MES', 'NTran', 'depth', 'duration', 'Rp',\\n        'Rs', 'Ts', 'logg', 'a', 'Rp/Rs', 'a/Rs', 'impact', 'SNR_DV', 'Sp',\\n        'Fit_Prov']\\ndf = df[cols]\\ndf.columns\\n\\ndf['Disp'] = df['Disp'].replace('PC', 1)\\ndf['Disp'] = df['Disp'].replace('FP', 0)\\n\\nX = df.iloc[:, 6:25]\\nY = df.iloc[:, 2]\\n\\nprint('Input Size:', X.shape)\\nprint('Output Size:', Y.shape)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Problem 2\n",
    "df = pd.read_csv('kplr_dr25_inj1_tces.csv', header = 0)\n",
    "\n",
    "print('Dataset Size: ')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "cols = ['TCE_ID', 'KIC', 'Disp', 'Score', 'period', 'epoch', 'NTL', 'SS', \n",
    "        'CO', 'EM', 'Expected_MES', 'MES', 'NTran', 'depth', 'duration', 'Rp',\n",
    "        'Rs', 'Ts', 'logg', 'a', 'Rp/Rs', 'a/Rs', 'impact', 'SNR_DV', 'Sp',\n",
    "        'Fit_Prov']\n",
    "df = df[cols]\n",
    "df.columns\n",
    "\n",
    "df['Disp'] = df['Disp'].replace('PC', 1)\n",
    "df['Disp'] = df['Disp'].replace('FP', 0)\n",
    "\n",
    "X = df.iloc[:, 6:25]\n",
    "Y = df.iloc[:, 2]\n",
    "\n",
    "print('Input Size:', X.shape)\n",
    "print('Output Size:', Y.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 350, num = 5)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 10)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.10, 0.25, 0.50, 1, 2, 4]\n",
    "\n",
    "# Minimum number of neighbors required for each node\n",
    "n_neighbors = [int(x) for x in np.linspace(start = 3, stop = 30, num = 10)]\n",
    "\n",
    "# Minimum Power parameter required for the Minkowski metric\n",
    "p = [float(x) for x in np.linspace(start = 1, stop = 5, num = 10)]\n",
    "\n",
    "\n",
    "\n",
    "# Maximizing the number of neurons in the hidden layers\n",
    "hidden_layer_sizes = [(50,), (100,), (50,50,50), (50,100,50)]\n",
    "\n",
    "# Activation functiosn for the hidden layers\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Solver for weight optimizations\n",
    "solver = ['sgd', 'adam']\n",
    "\n",
    "# Minimizing the regularization parameter\n",
    "alpha = [0.0001, 0.001, 0.01]\n",
    "\n",
    "# Maximizing the mini batch size\n",
    "batch_size = [32, 64, 96, 128]\n",
    "\n",
    "# Learning rate schedule for weight updates\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Setting up the k-fold\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 57.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = n_estimators,\n",
    "                  learning_rate = [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                  algorithm = ['SAMME', 'SAMME.R'])\n",
    "\n",
    "print('AdaBoost Classifier')\n",
    "abc_grid_search = GridSearchCV(abc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "abc_grid_result = abc_grid_search.fit(X, Y)\n",
    "abc_predict = abc_grid_search.predict(X)\n",
    "abc_predict_proba = pd.DataFrame(abc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "abc_accuracy = metrics.accuracy_score(Y, abc_predict)  \n",
    "abc_precision = metrics.precision_score(Y, abc_predict, pos_label=1)\n",
    "abc_recall = metrics.recall_score(Y, abc_predict, pos_label=1)  \n",
    "abc_f1 = metrics.f1_score(Y, abc_predict, pos_label=1)\n",
    "abc_auroc = metrics.roc_auc_score(Y, abc_predict)\n",
    "abc_aurpc = metrics.average_precision_score(Y, abc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('AdaBoostClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier\n",
      "Fitting 10 folds for each of 12000 candidates, totalling 120000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 22034 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 24184 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 26434 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 31234 tasks      | elapsed: 28.9min\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\backend\\queues.py\", line 150, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\backend\\reduction.py\", line 243, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\backend\\reduction.py\", line 236, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 284, in dump\n    return Pickler.dump(self, obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 437, in dump\n    self.save(obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\", line 902, in save_module_dict\n    StockPickler.save_dict(pickler, obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\", line 902, in save_module_dict\n    StockPickler.save_dict(pickler, obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 887, in _batch_setitems\n    save(v)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\", line 902, in save_module_dict\n    StockPickler.save_dict(pickler, obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 816, in save_list\n    self._batch_appends(obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 843, in _batch_appends\n    save(tmp[0])\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\", line 902, in save_module_dict\n    StockPickler.save_dict(pickler, obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 662, in save_reduce\n    save(state)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 786, in save_tuple\n    save(element)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 816, in save_list\n    self._batch_appends(obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 843, in _batch_appends\n    save(tmp[0])\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 549, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 638, in save_reduce\n    save(args)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 771, in save_tuple\n    save(element)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 504, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"D:\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\", line 902, in save_module_dict\n    StockPickler.save_dict(pickler, obj)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 856, in save_dict\n    self._batch_setitems(obj.items())\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 882, in _batch_setitems\n    save(v)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 510, in save\n    rv = reduce(obj)\n  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_memmapping_reducer.py\", line 339, in __call__\n    for dumped_filename in dump(a, filename):\n  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py\", line 502, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"D:\\Anaconda3\\lib\\pickle.py\", line 437, in dump\n    self.save(obj)\n  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py\", line 289, in save\n    wrapper.write_array(obj, self)\n  File \"D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py\", line 104, in write_array\n    pickler.file_handle.write(chunk.tostring('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9704539d1262>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DecisionTree Classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdtc_grid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdtc_grid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtc_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdtc_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtc_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdtc_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtc_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "dtc = DecisionTreeClassifier()\n",
    "    \n",
    "# Updating the param grid\n",
    "param_grid = dict(criterion = ['gini', 'entropy'],\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = ['auto', 'sqrt', 'log2', None],\n",
    "                  min_impurity_decrease = [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "print('DecisionTree Classifier')\n",
    "dtc_grid_search = GridSearchCV(dtc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "dtc_grid_result = dtc_grid_search.fit(X, Y)\n",
    "dtc_predict = dtc_grid_search.predict(X)\n",
    "dtc_predict_proba = pd.DataFrame(dtc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "dtc_accuracy = metrics.accuracy_score(Y, dtc_predict)  \n",
    "dtc_precision = metrics.precision_score(Y, dtc_predict, pos_label=1)\n",
    "dtc_recall = metrics.recall_score(Y, dtc_predict, pos_label=1)  \n",
    "dtc_f1 = metrics.f1_score(Y, dtc_predict, pos_label=1)\n",
    "dtc_auroc = metrics.roc_auc_score(Y, dtc_predict_proba[1])\n",
    "dtc_aurpc = metrics.average_precision_score(Y, dtc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('DecisionTreeClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "etc = ExtraTreesClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(bootstrap = ['True', 'False'],\n",
    "                  criterion = ['gini', 'entropy'],\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = ['auto', 'sqrt', 'log2', None],\n",
    "                  min_impurity_decrease = [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  n_estimators = n_estimators)\n",
    "\n",
    "print('ExtraTrees Classifier')\n",
    "etc_grid_search = GridSearchCV(etc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "etc_grid_result = etc_grid_search.fit(X, Y)\n",
    "etc_predict = etc_grid_search.predict(X)\n",
    "etc_predict_proba = pd.DataFrame(etc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "etc_accuracy = metrics.accuracy_score(Y, etc_predict)  \n",
    "etc_precision = metrics.precision_score(Y, etc_predict, pos_label=1)\n",
    "etc_recall = metrics.recall_score(Y, etc_predict, pos_label=1)  \n",
    "etc_f1 = metrics.f1_score(Y, etc_predict, pos_label=1)\n",
    "etc_auroc = metrics.roc_auc_score(Y, etc_predict_proba[1])\n",
    "etc_aurpc = metrics.average_precision_score(Y, etc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('ExtraTreesClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "gbc = GradientBoostingClassifier()\n",
    "        \n",
    "# Updating the param grid\n",
    "param_grid = dict(criterion = ['friedman_mse', 'mse', 'mae'],\n",
    "                  learning_rate = [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                  loss = ['deviance', 'exponential'],\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = ['auto', 'sqrt', 'log2', None],\n",
    "                  min_impurity_decrease = [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  n_estimators = n_estimators,\n",
    "                  subsample = [0.5, 1.0, 1.5])\n",
    "        \n",
    "print('GradientBoosting Classifier')\n",
    "gbc_grid_search = GridSearchCV(gbc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gbc_grid_result = gbc_grid_search.fit(X, Y)\n",
    "gbc_predict = gbc_grid_search.predict(X)\n",
    "gbc_predict_proba = pd.DataFrame(gbc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gbc_accuracy = metrics.accuracy_score(Y, gbc_predict)  \n",
    "gbc_precision = metrics.precision_score(Y, gbc_predict, pos_label=1)\n",
    "gbc_recall = metrics.recall_score(Y, gbc_predict, pos_label=1)  \n",
    "gbc_f1 = metrics.f1_score(Y, gbc_predict, pos_label=1)\n",
    "gbc_auroc = metrics.roc_auc_score(Y, gbc_predict_proba[1])\n",
    "gbc_aurpc = metrics.average_precision_score(Y, gbc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('GradientBoostingClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict()\n",
    "        \n",
    "print('Naive Bayes')\n",
    "gnb_grid_search = GridSearchCV(gnb, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gnb_grid_result = gnb_grid_search.fit(X, Y)\n",
    "gnb_predict = gnb_grid_search.predict(X)\n",
    "gnb_predict_proba = pd.DataFrame(gnb_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gnb_accuracy = metrics.accuracy_score(Y, gnb_predict)  \n",
    "gnb_precision = metrics.precision_score(Y, gnb_predict, pos_label=1)\n",
    "gnb_recall = metrics.recall_score(Y, gnb_predict, pos_label=1)  \n",
    "gnb_f1 = metrics.f1_score(Y, gnb_predict, pos_label=1)\n",
    "gnb_auroc = metrics.roc_auc_score(Y, gnb_predict_proba[1])\n",
    "gnb_aurpc = metrics.average_precision_score(Y, gnb_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('GaussianNB_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "gpc = GaussianProcessClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(optimizer = ['fmin', 'fmin_powell', 'fmin_cg', 'fmin_bfgs', 'fmin_ncg', 'fmin_l_bfgs_b', 'fmin_tnc',\n",
    "                               'fmin_cobyla', 'fmin_slsqp'])\n",
    "        \n",
    "print('GaussianProcess Classifier')\n",
    "gpc_grid_search = GridSearchCV(gpc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gpc_grid_result = gpc_grid_search.fit(X, Y)\n",
    "gpc_predict = gpc_grid_search.predict(X)\n",
    "gpc_predict_proba = pd.DataFrame(gpc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gpc_accuracy = metrics.accuracy_score(Y, gpc_predict)  \n",
    "gpc_precision = metrics.precision_score(Y, gpc_predict, pos_label=1)\n",
    "gpc_recall = metrics.recall_score(Y, gpc_predict, pos_label=1)  \n",
    "gpc_f1 = metrics.f1_score(Y, gpc_predict, pos_label=1)\n",
    "gpc_auroc = metrics.roc_auc_score(Y, gpc_predict_proba[1])\n",
    "gpc_aurpc = metrics.average_precision_score(Y, gpc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('GaussianProcessClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                  leaf_size = [10, 20, 30, 40, 50],\n",
    "                  metric = ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'wminkowski', 'seuclidean', 'mahalanobis'],\n",
    "                  n_neighbors = n_neighbors,\n",
    "                  p = p,\n",
    "                  weights = ['uniform', 'distance'])\n",
    "\n",
    "print('KNeighbors Classifier')\n",
    "knc_grid_search = GridSearchCV(knc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "knc_grid_result = knc_grid_search.fit(X, Y)\n",
    "knc_predict = knc_grid_search.predict(X)\n",
    "knc_predict_proba = pd.DataFrame(knc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "knc_accuracy = metrics.accuracy_score(Y, knc_predict)  \n",
    "knc_precision = metrics.precision_score(Y, knc_predict, pos_label=1)\n",
    "knc_recall = metrics.recall_score(Y, knc_predict, pos_label=1)  \n",
    "knc_f1 = metrics.f1_score(Y, knc_predict, pos_label=1)\n",
    "knc_auroc = metrics.roc_auc_score(Y, knc_predict_proba[1])\n",
    "knc_aurpc = metrics.average_precision_score(Y, knc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('KNeighborsClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(activation = ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                  alpha = [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1],\n",
    "                  batch_size = [32, 64, 96, 128, 256],\n",
    "                  hidden_layer_sizes = [(50, 100, 50), (100, 50, 100), (50, 100), (100, 50), (100, )],\n",
    "                  learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "                  learning_rate_init = [0.0001, 0.001, 0.01, 0.1],\n",
    "                  shuffle = ['True', 'False'],\n",
    "                  solver = ['lbfgs', 'sgd', 'adam'])\n",
    "\n",
    "print('Multi-layer Perceptron Classifier')\n",
    "mlp_grid_search = GridSearchCV(mlp, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "mlp_grid_result = mlp_grid_search.fit(X, Y)\n",
    "mlp_predict = mlp_grid_search.predict(X)\n",
    "mlp_predict_proba = pd.DataFrame(mlp_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "mlp_accuracy = metrics.accuracy_score(Y, mlp_predict)  \n",
    "mlp_precision = metrics.precision_score(Y, mlp_predict, pos_label=1)\n",
    "mlp_recall = metrics.recall_score(Y, mlp_predict, pos_label=1)  \n",
    "mlp_f1 = metrics.f1_score(Y, mlp_predict, pos_label=1)\n",
    "mlp_auroc = metrics.roc_auc_score(Y, mlp_predict_proba[1])\n",
    "mlp_aurpc = metrics.average_precision_score(Y, mlp_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('MLPClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(bootstrap = ['True', 'False'],\n",
    "                  criterion = ['gini', 'entropy'],\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = ['auto', 'sqrt', 'log2', None],\n",
    "                  min_impurity_decrease = [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  n_estimators = n_estimators)\n",
    "\n",
    "print('RandomForest Classifier')\n",
    "rfc_grid_search = GridSearchCV(rfc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "rfc_grid_result = rfc_grid_search.fit(X, Y)\n",
    "rfc_predict = rfc_grid_search.predict(X)\n",
    "rfc_predict_proba = pd.DataFrame(rfc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "rfc_accuracy = metrics.accuracy_score(Y, rfc_predict)  \n",
    "rfc_precision = metrics.precision_score(Y, rfc_predict, pos_label=1)\n",
    "rfc_recall = metrics.recall_score(Y, rfc_predict, pos_label=1)  \n",
    "rfc_f1 = metrics.f1_score(Y, rfc_predict, pos_label=1)\n",
    "rfc_auroc = metrics.roc_auc_score(Y, rfc_predict_proba[1])\n",
    "rfc_aurpc = metrics.average_precision_score(Y, rfc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('RandomForestClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Instantiate the model\n",
    "svc = SVC()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(C = [0.001, 0.01, 0.1, 1, 10],\n",
    "                  decision_function_shape = ['ovo', 'ovr'],\n",
    "                  degree = [0, 1, 2, 3, 4, 5, 6],\n",
    "                  gamma = [0.001, 0.01, 0.1, 1, 10],\n",
    "                  kernel = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "                  shrinking = ['True', 'False'])\n",
    "        \n",
    "print('ExtraTrees Classifier')\n",
    "svc_grid_search = GridSearchCV(svc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "svc_grid_result = svc_grid_search.fit(X, Y)\n",
    "svc_predict = svc_grid_search.predict(X)\n",
    "svc_predict_proba = pd.DataFrame(svc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "svc_accuracy = metrics.accuracy_score(Y, svc_predict)  \n",
    "svc_precision = metrics.precision_score(Y, svc_predict, pos_label=1)\n",
    "svc_recall = metrics.recall_score(Y, svc_predict, pos_label=1)  \n",
    "svc_f1 = metrics.f1_score(Y, svc_predict, pos_label=1)\n",
    "svc_auroc = metrics.roc_auc_score(Y, svc_predict_proba[1])\n",
    "svc_aurpc = metrics.average_precision_score(Y, svc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('SVC_Parameter_Tuning.db')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(booster = ['gbtree', 'gblinear', 'dart'],\n",
    "                  learning_rate = [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                  min_split_loss = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                  max_depth = max_depth,\n",
    "                  min_child_weight = [1, 3, 5],\n",
    "                  reg_lambda = [0.0001, 0.001, 0.01, 0.1, 0.0, 1.0],\n",
    "                  reg_alpha = [0.0001, 0.001, 0.01, 0.1, 0.0, 1.0],\n",
    "                  tree_method = ['exact', 'approx', 'hist'])\n",
    "\n",
    "print('XGBoost Classifier')\n",
    "xgb_grid_search = GridSearchCV(xgb, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "xgb_grid_result = xgb_grid_search.fit(X, Y)\n",
    "xgb_predict = xgb_grid_search.predict(X)\n",
    "xgb_predict_proba = pd.DataFrame(xgb_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "xgb_accuracy = metrics.accuracy_score(Y, xgb_predict)  \n",
    "xgb_precision = metrics.precision_score(Y, xgb_predict, pos_label=1)\n",
    "xgb_recall = metrics.recall_score(Y, xgb_predict, pos_label=1)  \n",
    "xgb_f1 = metrics.f1_score(Y, xgb_predict, pos_label=1)\n",
    "xgb_auroc = metrics.roc_auc_score(Y, xgb_predict_proba[1])\n",
    "xgb_aurpc = metrics.average_precision_score(Y, xgb_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('XGBClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['ADA Boost', 'Extra Trees', 'Random Forest', 'Gradient Boosting', 'XG Boost', 'Decision Tree',\n",
    "              'Multi Layer Perceptron', 'K Neighbors', 'Naive Bayes', 'Aggregate'],\n",
    "    'Accuracy' : [abc_accuracy, etc_accuracy, rfc_accuracy, gbc_accuracy, xgb_accuracy, dtc_accuracy,\n",
    "                  mlp_accuracy, knc_accuracy, gnb_accuracy, aggregate_accuracy],\n",
    "    'F1' : [abc_f1, etc_f1, rfc_f1, gbc_f1, xgb_f1, dtc_f1, mlp_f1, knc_f1, gnb_f1, aggregate_f1],\n",
    "    'AUROC' : [abc_auroc, etc_auroc, rfc_auroc, gbc_auroc, xgb_auroc, dtc_auroc, mlp_auroc, knc_auroc, \n",
    "               gnb_auroc, aggregate_auroc],\n",
    "    'AURPC' : [abc_aurpc, etc_aurpc, rfc_aurpc, gbc_aurpc, xgb_aurpc, dtc_aurpc, mlp_aurpc, knc_aurpc,\n",
    "               gnb_aurpc, aggregate_aurpc],\n",
    "    'Precision': [abc_precision, etc_precision, rfc_precision, gbc_precision, xgb_precision, dtc_precision, mlp_precision, \n",
    "                  knc_precision, gnb_precision, aggregate_precision],\n",
    "    'Recall' : [abc_recall, etc_recall, rfc_recall, gbc_recall, xgb_recall, dtc_recall, mlp_recall, knc_recall,\n",
    "                gnb_recall, aggregate_recall]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models = models.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "blankIndex=[''] * len(models)\n",
    "models.index=blankIndex\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "means = _grid_result.cv_results_['mean_test_score']\n",
    "stds = _grid_result.cv_results_['std_test_score']\n",
    "params = _grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
