{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import warnings\n",
    "\n",
    "import time as time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Read out 100 rows rather than the default value. \n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Not prinitng the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting the working path for data input and result outputs\n",
    "os.chdir('D:\\\\Spring 2019\\\\DS 440\\\\Data')\n",
    "\n",
    "# Setting a random seed for reproducability\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "(146294, 25)\n",
      "\n",
      "Cleaned Dataset Size:\n",
      "(145671, 15)\n",
      "\n",
      "Input Size: (145671, 13)\n",
      "Output Size: (145671,)\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "df = pd.read_csv('kplr_dr25_inj1_plti.csv', header = 0)\n",
    "\n",
    "#filenames = glob('D:\\Spring 2019\\DS 440\\Data\\kplr_dr25_inj*.csv')\n",
    "#df = pd.concat([pd.read_csv(f) for f in filenames], ignore_index = True)\n",
    "\n",
    "print('Dataset Size:')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "temp_df = df.iloc[:, 0:15]\n",
    "df_drop = temp_df[temp_df.isnull().any(axis=1)]\n",
    "temp_df = temp_df.drop(df_drop.index.values)\n",
    "temp_df = temp_df[temp_df.Recovered != 2]\n",
    "\n",
    "print('Cleaned Dataset Size:')\n",
    "print(temp_df.shape)\n",
    "print()\n",
    "\n",
    "X = temp_df.iloc[:, 1:14]\n",
    "Y = temp_df.iloc[:, 14]\n",
    "\n",
    "print('Input Size:', X.shape)\n",
    "print('Output Size:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: \n",
      "(45377, 26)\n",
      "\n",
      "Input Size: (45377, 19)\n",
      "Output Size: (45377,)\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "df = pd.read_csv('kplr_dr25_inj1_tces.csv', header = 0)\n",
    "\n",
    "print('Dataset Size: ')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "cols = ['TCE_ID', 'KIC', 'Disp', 'Score', 'period', 'epoch', 'NTL', 'SS', \n",
    "        'CO', 'EM', 'Expected_MES', 'MES', 'NTran', 'depth', 'duration', 'Rp',\n",
    "        'Rs', 'Ts', 'logg', 'a', 'Rp/Rs', 'a/Rs', 'impact', 'SNR_DV', 'Sp',\n",
    "        'Fit_Prov']\n",
    "df = df[cols]\n",
    "df.columns\n",
    "\n",
    "df['Disp'] = df['Disp'].replace('PC', 1)\n",
    "df['Disp'] = df['Disp'].replace('FP', 0)\n",
    "\n",
    "X = df.iloc[:, 6:25]\n",
    "Y = df.iloc[:, 2]\n",
    "\n",
    "print('Input Size:', X.shape)\n",
    "print('Output Size:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 350, num = 5)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 10)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.10, 0.25, 0.50, 1, 2, 4]\n",
    "\n",
    "# Minimum number of neighbors required for each node\n",
    "n_neighbors = [int(x) for x in np.linspace(start = 3, stop = 30, num = 10)]\n",
    "\n",
    "# Minimum Power parameter required for the Minkowski metric\n",
    "p = [float(x) for x in np.linspace(start = 1, stop = 5, num = 10)]\n",
    "\n",
    "# Minimum penalty parameter C of the error term\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Type of kernel algorithm\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "\n",
    "# Minimum kernel coefficient\n",
    "gamma = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Degree of the polynomial kernel function\n",
    "degree = [0, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Maximizing the number of neurons in the hidden layers\n",
    "hidden_layer_sizes = [(50,), (100,), (50,50,50), (50,100,50)]\n",
    "\n",
    "# Activation functiosn for the hidden layers\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "\n",
    "# Solver for weight optimizations\n",
    "solver = ['sgd', 'adam']\n",
    "\n",
    "# Minimizing the regularization parameter\n",
    "alpha = [0.0001, 0.001, 0.01]\n",
    "\n",
    "# Maximizing the mini batch size\n",
    "batch_size = [32, 64, 96, 128]\n",
    "\n",
    "# Learning rate schedule for weight updates\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "# Setting up the k-fold\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = n_estimators,\n",
    "                  learning_rate = learning_rate,\n",
    "                  algorithm = algorithm)\n",
    "\n",
    "print('AdaBoost Classifier')\n",
    "abc_grid_search = GridSearchCV(abc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "abc_grid_result = abc_grid_search.fit(X, Y)\n",
    "abc_predict = abc_grid_search.predict(X)\n",
    "abc_predict_proba = pd.DataFrame(abc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "abc_accuracy = metrics.accuracy_score(Y, abc_predict)  \n",
    "abc_precision = metrics.precision_score(Y, abc_predict, pos_label=1)\n",
    "abc_recall = metrics.recall_score(Y, abc_predict, pos_label=1)  \n",
    "abc_f1 = metrics.f1_score(Y, abc_predict, pos_label=1)\n",
    "abc_auroc = metrics.roc_auc_score(Y, abc_predict)\n",
    "abc_aurpc = metrics.average_precision_score(Y, abc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "    \n",
    "# Updating the param grid\n",
    "param_grid = dict(criterion = criterion,\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = max_features,\n",
    "                  max_leaf_nodes = max_leaf_nodes,\n",
    "                  min_impurity_decrease = min_impurity_decrease\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  min_weight_fraction_leaf = min_weight_fraction_leaf)\n",
    "\n",
    "print('DecisionTree Classifier')\n",
    "dtc_grid_search = GridSearchCV(dtc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "dtc_grid_result = dtc_grid_search.fit(X, Y)\n",
    "dtc_predict = dtc_grid_search.predict(X)\n",
    "dtc_predict_proba = pd.DataFrame(dtc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "dtc_accuracy = metrics.accuracy_score(Y, dtc_predict)  \n",
    "dtc_precision = metrics.precision_score(Y, dtc_predict, pos_label=1)\n",
    "dtc_recall = metrics.recall_score(Y, dtc_predict, pos_label=1)  \n",
    "dtc_f1 = metrics.f1_score(Y, dtc_predict, pos_label=1)\n",
    "dtc_auroc = metrics.roc_auc_score(Y, dtc_predict_proba[1])\n",
    "dtc_aurpc = metrics.average_precision_score(Y, dtc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(bootstrap = bootstrap,\n",
    "                  criterion = criterion,\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = max_features,\n",
    "                  max_leaf_nodes = max_leaf_nodes,\n",
    "                  min_impurity_decrease = min_impurity_decrease\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "                  n_estimators = n_estimators)\n",
    "\n",
    "print('ExtraTrees Classifier')\n",
    "etc_grid_search = GridSearchCV(etc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "etc_grid_result = etc_grid_search.fit(X, Y)\n",
    "etc_predict = etc_grid_search.predict(X)\n",
    "etc_predict_proba = pd.DataFrame(etc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "etc_accuracy = metrics.accuracy_score(Y, etc_predict)  \n",
    "etc_precision = metrics.precision_score(Y, etc_predict, pos_label=1)\n",
    "etc_recall = metrics.recall_score(Y, etc_predict, pos_label=1)  \n",
    "etc_f1 = metrics.f1_score(Y, etc_predict, pos_label=1)\n",
    "etc_auroc = metrics.roc_auc_score(Y, etc_predict_proba[1])\n",
    "etc_aurpc = metrics.average_precision_score(Y, etc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "        \n",
    "# Updating the param grid\n",
    "param_grid = dict(criterion = criterion,\n",
    "                  learning_rate = learning_rate,\n",
    "                  loss = loss,\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = max_features,\n",
    "                  max_leaf_nodes = max_leaf_nodes,\n",
    "                  min_impurity_decrease = min_impurity_decrease\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
    "                  n_estimators = n_estimators,\n",
    "                  subsample = subsample)\n",
    "        \n",
    "print('GradientBoosting Classifier')\n",
    "gbc_grid_search = GridSearchCV(gbc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gbc_grid_result = gbc_grid_search.fit(X, Y)\n",
    "gbc_predict = gbc_grid_search.predict(X)\n",
    "gbc_predict_proba = pd.DataFrame(gbc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gbc_accuracy = metrics.accuracy_score(Y, gbc_predict)  \n",
    "gbc_precision = metrics.precision_score(Y, gbc_predict, pos_label=1)\n",
    "gbc_recall = metrics.recall_score(Y, gbc_predict, pos_label=1)  \n",
    "gbc_f1 = metrics.f1_score(Y, gbc_predict, pos_label=1)\n",
    "gbc_auroc = metrics.roc_auc_score(Y, gbc_predict_proba[1])\n",
    "gbc_aurpc = metrics.average_precision_score(Y, gbc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict()\n",
    "        \n",
    "print('Naive Bayes')\n",
    "gnb_grid_search = GridSearchCV(gnb, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gnb_grid_result = gnb_grid_search.fit(X, Y)\n",
    "gnb_predict = gnb_grid_search.predict(X)\n",
    "gnb_predict_proba = pd.DataFrame(gnb_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gnb_accuracy = metrics.accuracy_score(Y, gnb_predict)  \n",
    "gnb_precision = metrics.precision_score(Y, gnb_predict, pos_label=1)\n",
    "gnb_recall = metrics.recall_score(Y, gnb_predict, pos_label=1)  \n",
    "gnb_f1 = metrics.f1_score(Y, gnb_predict, pos_label=1)\n",
    "gnb_auroc = metrics.roc_auc_score(Y, gnb_predict_proba[1])\n",
    "gnb_aurpc = metrics.average_precision_score(Y, gnb_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpc = GaussianProcessClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(optimizer = optimizer)\n",
    "        \n",
    "print('GaussianProcess Classifier')\n",
    "gpc_grid_search = GridSearchCV(gpc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gpc_grid_result = gpc_grid_search.fit(X, Y)\n",
    "gpc_predict = gpc_grid_search.predict(X)\n",
    "gpc_predict_proba = pd.DataFrame(gpc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gpc_accuracy = metrics.accuracy_score(Y, gpc_predict)  \n",
    "gpc_precision = metrics.precision_score(Y, gpc_predict, pos_label=1)\n",
    "gpc_recall = metrics.recall_score(Y, gpc_predict, pos_label=1)  \n",
    "gpc_f1 = metrics.f1_score(Y, gpc_predict, pos_label=1)\n",
    "gpc_auroc = metrics.roc_auc_score(Y, gpc_predict_proba[1])\n",
    "gpc_aurpc = metrics.average_precision_score(Y, gpc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(algorithm = algorithm,\n",
    "                  leaf_size = leaf_size,\n",
    "                  metric = metric\n",
    "                  n_neighbors = n_neighbors,\n",
    "                  p = p,\n",
    "                  weights = weights)\n",
    "\n",
    "print('KNeighbors Classifier')\n",
    "knc_grid_search = GridSearchCV(knc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "knc_grid_result = knc_grid_search.fit(X, Y)\n",
    "knc_predict = knc_grid_search.predict(X)\n",
    "knc_predict_proba = pd.DataFrame(knc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "knc_accuracy = metrics.accuracy_score(Y, knc_predict)  \n",
    "knc_precision = metrics.precision_score(Y, knc_predict, pos_label=1)\n",
    "knc_recall = metrics.recall_score(Y, knc_predict, pos_label=1)  \n",
    "knc_f1 = metrics.f1_score(Y, knc_predict, pos_label=1)\n",
    "knc_auroc = metrics.roc_auc_score(Y, knc_predict_proba[1])\n",
    "knc_aurpc = metrics.average_precision_score(Y, knc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(activation = activation,\n",
    "                  alpha = alpha,\n",
    "                  batch_size = batch_size,\n",
    "                  beta_1 = beta_1,\n",
    "                  beta_2 = beta_2,\n",
    "                  hidden_layer_sizes = hidden_layer_sizes,\n",
    "                  learning_rate = learning_rate,\n",
    "                  learning_rate_init = learning_rate_init,\n",
    "                  max_iter = max_iter,\n",
    "                  momentum = momentum,\n",
    "                  nesterovs_momentum = nesterovs_momentum,\n",
    "                  shuffle = shuffle,\n",
    "                  solver = solver)\n",
    "\n",
    "print('Multi-layer Perceptron Classifier')\n",
    "mlp_grid_search = GridSearchCV(mlp, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "mlp_grid_result = mlp_grid_search.fit(X, Y)\n",
    "mlp_predict = mlp_grid_search.predict(X)\n",
    "mlp_predict_proba = pd.DataFrame(mlp_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "mlp_accuracy = metrics.accuracy_score(Y, mlp_predict)  \n",
    "mlp_precision = metrics.precision_score(Y, mlp_predict, pos_label=1)\n",
    "mlp_recall = metrics.recall_score(Y, mlp_predict, pos_label=1)  \n",
    "mlp_f1 = metrics.f1_score(Y, mlp_predict, pos_label=1)\n",
    "mlp_auroc = metrics.roc_auc_score(Y, mlp_predict_proba[1])\n",
    "mlp_aurpc = metrics.average_precision_score(Y, mlp_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(bootstrap = bootstrap,\n",
    "                  criterion = criterion,\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = max_features,\n",
    "                  max_leaf_nodes = max_leaf_nodes,\n",
    "                  min_impurity_decrease = min_impurity_decrease,\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  n_estimators = n_estimators)\n",
    "\n",
    "print('RandomForest Classifier')\n",
    "rfc_grid_search = GridSearchCV(rfc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "rfc_grid_result = rfc_grid_search.fit(X, Y)\n",
    "rfc_predict = rfc_grid_search.predict(X)\n",
    "rfc_predict_proba = pd.DataFrame(rfc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "rfc_accuracy = metrics.accuracy_score(Y, rfc_predict)  \n",
    "rfc_precision = metrics.precision_score(Y, rfc_predict, pos_label=1)\n",
    "rfc_recall = metrics.recall_score(Y, rfc_predict, pos_label=1)  \n",
    "rfc_f1 = metrics.f1_score(Y, rfc_predict, pos_label=1)\n",
    "rfc_auroc = metrics.roc_auc_score(Y, rfc_predict_proba[1])\n",
    "rfc_aurpc = metrics.average_precision_score(Y, rfc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC() #C, kernel, gamma, degree, shrinking, decision_function_shape\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(C = C,\n",
    "                  decision_function_shape = decision_function_shape,\n",
    "                  degree = degree,\n",
    "                  gamma = gamma,\n",
    "                  kernel = kernel,\n",
    "                  shrinking = shrinking)\n",
    "        \n",
    "print('ExtraTrees Classifier')\n",
    "svc_grid_search = GridSearchCV(svc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "svc_grid_result = svc_grid_search.fit(X, Y)\n",
    "svc_predict = svc_grid_search.predict(X)\n",
    "svc_predict_proba = pd.DataFrame(svc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "svc_accuracy = metrics.accuracy_score(Y, svc_predict)  \n",
    "svc_precision = metrics.precision_score(Y, svc_predict, pos_label=1)\n",
    "svc_recall = metrics.recall_score(Y, svc_predict, pos_label=1)  \n",
    "svc_f1 = metrics.f1_score(Y, svc_predict, pos_label=1)\n",
    "svc_auroc = metrics.roc_auc_score(Y, svc_predict_proba[1])\n",
    "svc_aurpc = metrics.average_precision_score(Y, svc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(booster = booster,\n",
    "                  learning_rate = learning_rate,\n",
    "                  min_split_loss = min_split_loss,\n",
    "                  max_depth = max_depth,\n",
    "                  min_child_weight = min_child_weight,\n",
    "                  max_delta_step = max_delta_step,\n",
    "                  reg_lambda = reg_lambda,\n",
    "                  reg_alpha = reg_alpha,\n",
    "                  tree_method = tree_method,\n",
    "                  updater = updater,\n",
    "                  max_leaves = max_leaves,\n",
    "                  max_bin = max_bin)\n",
    "\n",
    "print('XGBoost Classifier')\n",
    "xgb_grid_search = GridSearchCV(xgb, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "xgb_grid_result = xgb_grid_search.fit(X, Y)\n",
    "xgb_predict = xgb_grid_search.predict(X)\n",
    "xgb_predict_proba = pd.DataFrame(xgb_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "xgb_accuracy = metrics.accuracy_score(Y, xgb_predict)  \n",
    "xgb_precision = metrics.precision_score(Y, xgb_predict, pos_label=1)\n",
    "xgb_recall = metrics.recall_score(Y, xgb_predict, pos_label=1)  \n",
    "xgb_f1 = metrics.f1_score(Y, xgb_predict, pos_label=1)\n",
    "xgb_auroc = metrics.roc_auc_score(Y, xgb_predict_proba[1])\n",
    "xgb_aurpc = metrics.average_precision_score(Y, xgb_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['ADA Boost', 'Extra Trees', 'Random Forest', 'Gradient Boosting', 'XG Boost', 'Decision Tree',\n",
    "              'Multi Layer Perceptron', 'K Neighbors', 'Naive Bayes', 'Aggregate'],\n",
    "    'Accuracy' : [abc_accuracy, etc_accuracy, rfc_accuracy, gbc_accuracy, xgb_accuracy, dtc_accuracy,\n",
    "                  mlp_accuracy, knc_accuracy, gnb_accuracy, aggregate_accuracy],\n",
    "    'F1' : [abc_f1, etc_f1, rfc_f1, gbc_f1, xgb_f1, dtc_f1, mlp_f1, knc_f1, gnb_f1, aggregate_f1],\n",
    "    'AUROC' : [abc_auroc, etc_auroc, rfc_auroc, gbc_auroc, xgb_auroc, dtc_auroc, mlp_auroc, knc_auroc, \n",
    "               gnb_auroc, aggregate_auroc],\n",
    "    'AURPC' : [abc_aurpc, etc_aurpc, rfc_aurpc, gbc_aurpc, xgb_aurpc, dtc_aurpc, mlp_aurpc, knc_aurpc,\n",
    "               gnb_aurpc, aggregate_aurpc],\n",
    "    'Precision': [abc_precision, etc_precision, rfc_precision, gbc_precision, xgb_precision, dtc_precision, mlp_precision, \n",
    "                  knc_precision, gnb_precision, aggregate_precision],\n",
    "    'Recall' : [abc_recall, etc_recall, rfc_recall, gbc_recall, xgb_recall, dtc_recall, mlp_recall, knc_recall,\n",
    "                gnb_recall, aggregate_recall]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models = models.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "blankIndex=[''] * len(models)\n",
    "models.index=blankIndex\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "means = _grid_result.cv_results_['mean_test_score']\n",
    "stds = _grid_result.cv_results_['std_test_score']\n",
    "params = _grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
