{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "# To Read out 100 rows rather than the default value. \n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Not prinitng the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting the working path for data input and result outputs\n",
    "os.chdir('D:\\\\Spring 2019\\\\DS 440\\\\Data')\n",
    "\n",
    "# Setting a random seed for reproducability\n",
    "np.random.seed(7)\n",
    "\n",
    "# Setting up the k-fold\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 7)\n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER = /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Problem 1\\ndf = pd.read_csv('kplr_dr25_inj1_plti.csv', header = 0)\\n\\nprint('Dataset Size:')\\nprint(df.shape)\\nprint()\\n\\ntemp_df = df.iloc[:, 0:15]\\ndf_drop = temp_df[temp_df.isnull().any(axis=1)]\\ntemp_df = temp_df.drop(df_drop.index.values)\\ntemp_df = temp_df[temp_df.Recovered != 2]\\n\\nprint('Cleaned Dataset Size:')\\nprint(temp_df.shape)\\nprint()\\n\\n#X = temp_df.iloc[:, 1:14]\\n#Y = temp_df.iloc[:, 14]\\n\\nX_cols = ['i_period', 'i_epoch', 'N_Transit', 'i_depth', 'i_dur', 'i_ror', 'i_dor', 'Expected_MES']\\nY_cols = ['Recovered']\\n\\nX = temp_df[X_cols]\\nY = temp_df[Y_cols]\\n\\nprint('Input Size:', X.shape)\\nprint('Output Size:', Y.shape)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Problem 1\n",
    "df = pd.read_csv('kplr_dr25_inj1_plti.csv', header = 0)\n",
    "\n",
    "print('Dataset Size:')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "temp_df = df.iloc[:, 0:15]\n",
    "df_drop = temp_df[temp_df.isnull().any(axis=1)]\n",
    "temp_df = temp_df.drop(df_drop.index.values)\n",
    "temp_df = temp_df[temp_df.Recovered != 2]\n",
    "\n",
    "print('Cleaned Dataset Size:')\n",
    "print(temp_df.shape)\n",
    "print()\n",
    "\n",
    "#X = temp_df.iloc[:, 1:14]\n",
    "#Y = temp_df.iloc[:, 14]\n",
    "\n",
    "X_cols = ['i_period', 'i_epoch', 'N_Transit', 'i_depth', 'i_dur', 'i_ror', 'i_dor', 'Expected_MES']\n",
    "Y_cols = ['Recovered']\n",
    "\n",
    "X = temp_df[X_cols]\n",
    "Y = temp_df[Y_cols]\n",
    "\n",
    "print('Input Size:', X.shape)\n",
    "print('Output Size:', Y.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: \n",
      "(45377, 26)\n",
      "\n",
      "Input Size: (45377, 16)\n",
      "Output Size: (45377,)\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "df = pd.read_csv('kplr_dr25_inj1_tces.csv', header = 0)\n",
    "\n",
    "print('Dataset Size: ')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "cols = ['TCE_ID', 'KIC', 'Disp', 'Score', 'period', 'epoch', 'NTL', 'SS', 'CO', 'EM', 'Expected_MES', 'MES', 'NTran',\n",
    "        'depth', 'duration', 'Rp', 'Rs', 'Ts', 'logg', 'a', 'Rp/Rs', 'a/Rs', 'impact', 'SNR_DV', 'Sp', 'Fit_Prov']\n",
    "df = df[cols]\n",
    "df.columns\n",
    "\n",
    "df['Disp'] = df['Disp'].replace('PC', 1)\n",
    "df['Disp'] = df['Disp'].replace('FP', 0)\n",
    "\n",
    "X = df.iloc[:, 10:]\n",
    "Y = df.iloc[:, 2]\n",
    "\n",
    "print('Input Size:', X.shape)\n",
    "print('Output Size:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 15.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = [int(x) for x in np.linspace(start = 10, stop = 350, num = 5)],\n",
    "                  learning_rate = [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                  algorithm = ['SAMME', 'SAMME.R'])\n",
    "\n",
    "print('AdaBoost Classifier')\n",
    "abc_grid_search = GridSearchCV(abc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "abc_grid_result = abc_grid_search.fit(X, Y)\n",
    "abc_predict = abc_grid_search.predict(X)\n",
    "abc_predict_proba = pd.DataFrame(abc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "abc_accuracy = metrics.accuracy_score(Y, abc_predict)  \n",
    "abc_precision = metrics.precision_score(Y, abc_predict, pos_label=1)\n",
    "abc_recall = metrics.recall_score(Y, abc_predict, pos_label=1)  \n",
    "abc_f1 = metrics.f1_score(Y, abc_predict, pos_label=1)\n",
    "abc_auroc = metrics.roc_auc_score(Y, abc_predict)\n",
    "abc_aurpc = metrics.average_precision_score(Y, abc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('AdaBoostClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier\n",
      "Fitting 5 folds for each of 9000 candidates, totalling 45000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 688 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1688 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3088 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4406 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5506 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6631 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8131 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9636 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11335 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 13230 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 15352 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 17624 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 20115 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 22807 tasks      | elapsed:  7.5min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b95a681bec72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DecisionTree Classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdtc_grid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdtc_grid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtc_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdtc_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtc_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdtc_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtc_grid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "dtc = DecisionTreeClassifier()\n",
    "    \n",
    "# Updating the param grid\n",
    "param_grid = dict(criterion = ['gini', 'entropy'],\n",
    "                  max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 5)],\n",
    "                  max_features = ['sqrt', 'log2', None],\n",
    "                  min_impurity_decrease = [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  min_samples_split = [2, 4, 6, 8, 10],\n",
    "                  min_samples_leaf = [0.10, 0.25, 0.50, 1, 2, 4])\n",
    "\n",
    "print('DecisionTree Classifier')\n",
    "dtc_grid_search = GridSearchCV(dtc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "dtc_grid_result = dtc_grid_search.fit(X, Y)\n",
    "dtc_predict = dtc_grid_search.predict(X)\n",
    "dtc_predict_proba = pd.DataFrame(dtc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "dtc_accuracy = metrics.accuracy_score(Y, dtc_predict)  \n",
    "dtc_precision = metrics.precision_score(Y, dtc_predict, pos_label=1)\n",
    "dtc_recall = metrics.recall_score(Y, dtc_predict, pos_label=1)  \n",
    "dtc_f1 = metrics.f1_score(Y, dtc_predict, pos_label=1)\n",
    "dtc_auroc = metrics.roc_auc_score(Y, dtc_predict_proba[1])\n",
    "dtc_aurpc = metrics.average_precision_score(Y, dtc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('DecisionTreeClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "etc = ExtraTreesClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 5)],\n",
    "                  max_features = ['sqrt', 'log2', None],\n",
    "                  min_impurity_decrease = [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  min_samples_split = [2, 4, 6, 8, 10],\n",
    "                  min_samples_leaf = [0.10, 0.25, 0.50, 1, 2, 4],\n",
    "                  n_estimators = [int(x) for x in np.linspace(start = 10, stop = 350, num = 5)])\n",
    "\n",
    "print('ExtraTrees Classifier')\n",
    "etc_grid_search = GridSearchCV(etc, param_grid, scoring = 'accuracy', n_jobs = 4, cv = kfold, verbose = 1)\n",
    "etc_grid_result = etc_grid_search.fit(X, Y)\n",
    "etc_predict = etc_grid_search.predict(X)\n",
    "etc_predict_proba = pd.DataFrame(etc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "etc_accuracy = metrics.accuracy_score(Y, etc_predict)  \n",
    "etc_precision = metrics.precision_score(Y, etc_predict, pos_label=1)\n",
    "etc_recall = metrics.recall_score(Y, etc_predict, pos_label=1)  \n",
    "etc_f1 = metrics.f1_score(Y, etc_predict, pos_label=1)\n",
    "etc_auroc = metrics.roc_auc_score(Y, etc_predict_proba[1])\n",
    "etc_aurpc = metrics.average_precision_score(Y, etc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('ExtraTreesClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict()\n",
    "        \n",
    "print('Naive Bayes')\n",
    "gnb_grid_search = GridSearchCV(gnb, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gnb_grid_result = gnb_grid_search.fit(X, Y)\n",
    "gnb_predict = gnb_grid_search.predict(X)\n",
    "gnb_predict_proba = pd.DataFrame(gnb_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gnb_accuracy = metrics.accuracy_score(Y, gnb_predict)  \n",
    "gnb_precision = metrics.precision_score(Y, gnb_predict, pos_label=1)\n",
    "gnb_recall = metrics.recall_score(Y, gnb_predict, pos_label=1)  \n",
    "gnb_f1 = metrics.f1_score(Y, gnb_predict, pos_label=1)\n",
    "gnb_auroc = metrics.roc_auc_score(Y, gnb_predict_proba[1])\n",
    "gnb_aurpc = metrics.average_precision_score(Y, gnb_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('GaussianNB_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "gpc = GaussianProcessClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(max_iter_predict = [50, 100, 150, 200])\n",
    "        \n",
    "print('GaussianProcess Classifier')\n",
    "gpc_grid_search = GridSearchCV(gpc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gpc_grid_result = gpc_grid_search.fit(X, Y)\n",
    "gpc_predict = gpc_grid_search.predict(X)\n",
    "gpc_predict_proba = pd.DataFrame(gpc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gpc_accuracy = metrics.accuracy_score(Y, gpc_predict)  \n",
    "gpc_precision = metrics.precision_score(Y, gpc_predict, pos_label=1)\n",
    "gpc_recall = metrics.recall_score(Y, gpc_predict, pos_label=1)  \n",
    "gpc_f1 = metrics.f1_score(Y, gpc_predict, pos_label=1)\n",
    "gpc_auroc = metrics.roc_auc_score(Y, gpc_predict_proba[1])\n",
    "gpc_aurpc = metrics.average_precision_score(Y, gpc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('GaussianProcessClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "gbc = GradientBoostingClassifier()\n",
    "        \n",
    "# Updating the param grid\n",
    "param_grid = dict(criterion = ['friedman_mse', 'mse', 'mae'],\n",
    "                  learning_rate = [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                  loss = ['deviance', 'exponential'],\n",
    "                  max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 5)],\n",
    "                  max_features = ['sqrt', 'log2', None],\n",
    "                  min_impurity_decrease = [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  min_samples_split = [2, 4, 6, 8, 10],\n",
    "                  min_samples_leaf = [0.10, 0.25, 0.50, 1, 2, 4],\n",
    "                  n_estimators = [int(x) for x in np.linspace(start = 10, stop = 350, num = 5)],\n",
    "                  subsample = [0.5, 1.0])\n",
    "        \n",
    "print('GradientBoosting Classifier')\n",
    "gbc_grid_search = GridSearchCV(gbc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "gbc_grid_result = gbc_grid_search.fit(X, Y)\n",
    "gbc_predict = gbc_grid_search.predict(X)\n",
    "gbc_predict_proba = pd.DataFrame(gbc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "gbc_accuracy = metrics.accuracy_score(Y, gbc_predict)  \n",
    "gbc_precision = metrics.precision_score(Y, gbc_predict, pos_label=1)\n",
    "gbc_recall = metrics.recall_score(Y, gbc_predict, pos_label=1)  \n",
    "gbc_f1 = metrics.f1_score(Y, gbc_predict, pos_label=1)\n",
    "gbc_auroc = metrics.roc_auc_score(Y, gbc_predict_proba[1])\n",
    "gbc_aurpc = metrics.average_precision_score(Y, gbc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('GradientBoostingClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "knc = KNeighborsClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                  leaf_size = [10, 20, 30, 40, 50],\n",
    "                  metric = ['euclidean', 'manhattan', 'chebyshev', 'minkowski'],\n",
    "                  n_neighbors = [int(x) for x in np.linspace(start = 3, stop = 30, num = 5)],\n",
    "                  p = [float(x) for x in np.linspace(start = 1, stop = 5, num = 10)],\n",
    "                  weights = ['uniform', 'distance'])\n",
    "\n",
    "print('KNeighbors Classifier')\n",
    "knc_grid_search = GridSearchCV(knc, param_grid, scoring = 'accuracy', n_jobs = 4, cv = kfold, verbose = 1)\n",
    "knc_grid_result = knc_grid_search.fit(X, Y)\n",
    "knc_predict = knc_grid_search.predict(X)\n",
    "knc_predict_proba = pd.DataFrame(knc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "knc_accuracy = metrics.accuracy_score(Y, knc_predict)  \n",
    "knc_precision = metrics.precision_score(Y, knc_predict, pos_label=1)\n",
    "knc_recall = metrics.recall_score(Y, knc_predict, pos_label=1)  \n",
    "knc_f1 = metrics.f1_score(Y, knc_predict, pos_label=1)\n",
    "knc_auroc = metrics.roc_auc_score(Y, knc_predict_proba[1])\n",
    "knc_aurpc = metrics.average_precision_score(Y, knc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('KNeighborsClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(activation = ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                  alpha = [0.0005, 0.0001, 0.005, 0.001, 0.01, 0.1],\n",
    "                  batch_size = [32, 64, 96, 128, 256],\n",
    "                  hidden_layer_sizes = [(50, 100, 50), (50, 100), (100, 50)],\n",
    "                  learning_rate = ['constant', 'invscaling', 'adaptive'],\n",
    "                  learning_rate_init = [0.0001, 0.001, 0.01, 0.1],\n",
    "                  max_iter = [250, 500, 1000],\n",
    "                  solver = ['lbfgs', 'sgd', 'adam'])\n",
    "\n",
    "print('Multi-layer Perceptron Classifier')\n",
    "mlp_grid_search = GridSearchCV(mlp, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "mlp_grid_result = mlp_grid_search.fit(X, Y)\n",
    "mlp_predict = mlp_grid_search.predict(X)\n",
    "mlp_predict_proba = pd.DataFrame(mlp_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "mlp_accuracy = metrics.accuracy_score(Y, mlp_predict)  \n",
    "mlp_precision = metrics.precision_score(Y, mlp_predict, pos_label=1)\n",
    "mlp_recall = metrics.recall_score(Y, mlp_predict, pos_label=1)  \n",
    "mlp_f1 = metrics.f1_score(Y, mlp_predict, pos_label=1)\n",
    "mlp_auroc = metrics.roc_auc_score(Y, mlp_predict_proba[1])\n",
    "mlp_aurpc = metrics.average_precision_score(Y, mlp_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('MLPClassifier_Parameter_Tuning.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 5)],\n",
    "                  max_features = ['sqrt', 'log2', None],\n",
    "                  min_impurity_decrease = [0.00001, 0.0001, 0.001, 0.01, 0.1],\n",
    "                  min_samples_split = [2, 4, 6, 8, 10],\n",
    "                  min_samples_leaf = [0.10, 0.25, 0.50, 1, 2, 4],\n",
    "                  n_estimators = [int(x) for x in np.linspace(start = 10, stop = 350, num = 5)])\n",
    "\n",
    "print('RandomForest Classifier')\n",
    "rfc_grid_search = GridSearchCV(rfc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "rfc_grid_result = rfc_grid_search.fit(X, Y)\n",
    "rfc_predict = rfc_grid_search.predict(X)\n",
    "rfc_predict_proba = pd.DataFrame(rfc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "rfc_accuracy = metrics.accuracy_score(Y, rfc_predict)  \n",
    "rfc_precision = metrics.precision_score(Y, rfc_predict, pos_label=1)\n",
    "rfc_recall = metrics.recall_score(Y, rfc_predict, pos_label=1)  \n",
    "rfc_f1 = metrics.f1_score(Y, rfc_predict, pos_label=1)\n",
    "rfc_auroc = metrics.roc_auc_score(Y, rfc_predict_proba[1])\n",
    "rfc_aurpc = metrics.average_precision_score(Y, rfc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('RandomForestClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Instantiate the model\n",
    "svc = SVC()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(C = [0.001, 0.01, 0.1, 1, 10],\n",
    "                  decision_function_shape = ['ovo', 'ovr'],\n",
    "                  degree = [0, 1, 2, 3, 4, 5, 6],\n",
    "                  gamma = [0.001, 0.01, 0.1, 1, 10],\n",
    "                  kernel = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "                  shrinking = ['True', 'False'])\n",
    "        \n",
    "print('ExtraTrees Classifier')\n",
    "svc_grid_search = GridSearchCV(svc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "svc_grid_result = svc_grid_search.fit(X, Y)\n",
    "svc_predict = svc_grid_search.predict(X)\n",
    "svc_predict_proba = pd.DataFrame(svc_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "svc_accuracy = metrics.accuracy_score(Y, svc_predict)  \n",
    "svc_precision = metrics.precision_score(Y, svc_predict, pos_label=1)\n",
    "svc_recall = metrics.recall_score(Y, svc_predict, pos_label=1)  \n",
    "svc_f1 = metrics.f1_score(Y, svc_predict, pos_label=1)\n",
    "svc_auroc = metrics.roc_auc_score(Y, svc_predict_proba[1])\n",
    "svc_aurpc = metrics.average_precision_score(Y, svc_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('SVC_Parameter_Tuning.db')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(learning_rate = [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "                  min_split_loss = [0.0, 0.2, 0.4,],\n",
    "                  max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 5)],\n",
    "                  min_child_weight = [1, 3, 5],\n",
    "                  reg_lambda = [0.0001, 0.001, 0.01, 0.1],\n",
    "                  reg_alpha = [0.0001, 0.001, 0.01, 0.1])\n",
    "\n",
    "print('XGBoost Classifier')\n",
    "xgb_grid_search = GridSearchCV(xgb, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "xgb_grid_result = xgb_grid_search.fit(X, Y)\n",
    "xgb_predict = xgb_grid_search.predict(X)\n",
    "xgb_predict_proba = pd.DataFrame(xgb_grid_search.predict_proba(X))\n",
    "\n",
    "# Store metrics\n",
    "xgb_accuracy = metrics.accuracy_score(Y, xgb_predict)  \n",
    "xgb_precision = metrics.precision_score(Y, xgb_predict, pos_label=1)\n",
    "xgb_recall = metrics.recall_score(Y, xgb_predict, pos_label=1)  \n",
    "xgb_f1 = metrics.f1_score(Y, xgb_predict, pos_label=1)\n",
    "xgb_auroc = metrics.roc_auc_score(Y, xgb_predict_proba[1])\n",
    "xgb_aurpc = metrics.average_precision_score(Y, xgb_predict, pos_label=1)\n",
    "\n",
    "dill.dump_session('XGBClassifier_Parameter_Tuning.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['ADA Boost', 'Extra Trees', 'Random Forest', 'Gradient Boosting', 'XG Boost', 'Decision Tree',\n",
    "              'Multi Layer Perceptron', 'K Neighbors', 'Naive Bayes', 'Aggregate'],\n",
    "    'Accuracy' : [abc_accuracy, etc_accuracy, rfc_accuracy, gbc_accuracy, xgb_accuracy, dtc_accuracy,\n",
    "                  mlp_accuracy, knc_accuracy, gnb_accuracy, aggregate_accuracy],\n",
    "    'F1' : [abc_f1, etc_f1, rfc_f1, gbc_f1, xgb_f1, dtc_f1, mlp_f1, knc_f1, gnb_f1, aggregate_f1],\n",
    "    'AUROC' : [abc_auroc, etc_auroc, rfc_auroc, gbc_auroc, xgb_auroc, dtc_auroc, mlp_auroc, knc_auroc, \n",
    "               gnb_auroc, aggregate_auroc],\n",
    "    'AURPC' : [abc_aurpc, etc_aurpc, rfc_aurpc, gbc_aurpc, xgb_aurpc, dtc_aurpc, mlp_aurpc, knc_aurpc,\n",
    "               gnb_aurpc, aggregate_aurpc],\n",
    "    'Precision': [abc_precision, etc_precision, rfc_precision, gbc_precision, xgb_precision, dtc_precision, mlp_precision, \n",
    "                  knc_precision, gnb_precision, aggregate_precision],\n",
    "    'Recall' : [abc_recall, etc_recall, rfc_recall, gbc_recall, xgb_recall, dtc_recall, mlp_recall, knc_recall,\n",
    "                gnb_recall, aggregate_recall]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models = models.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "blankIndex=[''] * len(models)\n",
    "models.index=blankIndex\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "means = _grid_result.cv_results_['mean_test_score']\n",
    "stds = _grid_result.cv_results_['std_test_score']\n",
    "params = _grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
