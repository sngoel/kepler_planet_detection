{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import warnings\n",
    "\n",
    "import time as time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Read out 100 rows rather than the default value. \n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Not prinitng the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting the working path for data input and result outputs\n",
    "os.chdir('D:\\\\Spring 2019\\\\DS 440\\\\Data')\n",
    "\n",
    "# Setting a random seed for reproducability\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "(146294, 25)\n",
      "\n",
      "Cleaned Dataset Size:\n",
      "(145671, 15)\n",
      "\n",
      "Input Size: (145671, 13)\n",
      "Output Size: (145671,)\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "df = pd.read_csv('kplr_dr25_inj1_plti.csv', header = 0)\n",
    "\n",
    "#filenames = glob('D:\\Spring 2019\\DS 440\\Data\\kplr_dr25_inj*.csv')\n",
    "#df = pd.concat([pd.read_csv(f) for f in filenames], ignore_index = True)\n",
    "\n",
    "print('Dataset Size:')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "temp_df = df.iloc[:, 0:15]\n",
    "df_drop = temp_df[temp_df.isnull().any(axis=1)]\n",
    "temp_df = temp_df.drop(df_drop.index.values)\n",
    "temp_df = temp_df[temp_df.Recovered != 2]\n",
    "\n",
    "print('Cleaned Dataset Size:')\n",
    "print(temp_df.shape)\n",
    "print()\n",
    "\n",
    "X = temp_df.iloc[:, 1:14]\n",
    "Y = temp_df.iloc[:, 14]\n",
    "\n",
    "print('Input Size:', X.shape)\n",
    "print('Output Size:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: \n",
      "(45377, 26)\n",
      "\n",
      "Input Size: (45377, 19)\n",
      "Output Size: (45377,)\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "df = pd.read_csv('kplr_dr25_inj1_tces.csv', header = 0)\n",
    "\n",
    "print('Dataset Size: ')\n",
    "print(df.shape)\n",
    "print()\n",
    "\n",
    "cols = ['TCE_ID', 'KIC', 'Disp', 'Score', 'period', 'epoch', 'NTL', 'SS', \n",
    "        'CO', 'EM', 'Expected_MES', 'MES', 'NTran', 'depth', 'duration', 'Rp',\n",
    "        'Rs', 'Ts', 'logg', 'a', 'Rp/Rs', 'a/Rs', 'impact', 'SNR_DV', 'Sp',\n",
    "        'Fit_Prov']\n",
    "df = df[cols]\n",
    "df.columns\n",
    "\n",
    "df['Disp'] = df['Disp'].replace('PC', 1)\n",
    "df['Disp'] = df['Disp'].replace('FP', 0)\n",
    "\n",
    "X = df.iloc[:, 10:25]\n",
    "Y = df.iloc[:, 2]\n",
    "\n",
    "print('Input Size:', X.shape)\n",
    "print('Output Size:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "dtc = DecisionTreeClassifier()\n",
    "etc = ExtraTreesClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "gnb = GaussianNB()\n",
    "gpc = GaussianProcessClassifier()\n",
    "knc = KNeighborsClassifier()\n",
    "mlp = MLPClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "svc = SVC()\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "kFold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  70.46\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "abc_predict = cross_val_predict(abc, X, Y, cv = kFold)\n",
    "abc_predict_proba = pd.DataFrame(cross_val_predict(abc, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "abc_accuracy = metrics.accuracy_score(Y, abc_predict)  \n",
    "abc_precision = metrics.precision_score(Y, abc_predict, pos_label=1)\n",
    "abc_recall = metrics.recall_score(Y, abc_predict, pos_label=1)  \n",
    "abc_f1 = metrics.f1_score(Y, abc_predict, pos_label=1)\n",
    "abc_auroc = metrics.roc_auc_score(Y, abc_predict_proba[1])\n",
    "abc_aurpc = metrics.average_precision_score(Y, abc_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  3.64\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dtc_predict = cross_val_predict(dtc, X, Y, cv = kFold)\n",
    "dtc_predict_proba = pd.DataFrame(cross_val_predict(dtc, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "dtc_accuracy = metrics.accuracy_score(Y, dtc_predict)  \n",
    "dtc_precision = metrics.precision_score(Y, dtc_predict, pos_label=1)\n",
    "dtc_recall = metrics.recall_score(Y, dtc_predict, pos_label=1)  \n",
    "dtc_f1 = metrics.f1_score(Y, dtc_predict, pos_label=1)\n",
    "dtc_auroc = metrics.roc_auc_score(Y, dtc_predict_proba[1])\n",
    "dtc_aurpc = metrics.average_precision_score(Y, dtc_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  2.36\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "etc_predict = cross_val_predict(etc, X, Y, cv = kFold)\n",
    "etc_predict_proba = pd.DataFrame(cross_val_predict(etc, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "etc_accuracy = metrics.accuracy_score(Y, etc_predict)  \n",
    "etc_precision = metrics.precision_score(Y, etc_predict, pos_label=1)\n",
    "etc_recall = metrics.recall_score(Y, etc_predict, pos_label=1)  \n",
    "etc_f1 = metrics.f1_score(Y, etc_predict, pos_label=1)\n",
    "etc_auroc = metrics.roc_auc_score(Y, etc_predict_proba[1])\n",
    "etc_aurpc = metrics.average_precision_score(Y, etc_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  65.42\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gbc_predict = cross_val_predict(gbc, X, Y, cv = kFold)\n",
    "gbc_predict_proba = pd.DataFrame(cross_val_predict(gbc, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "gbc_accuracy = metrics.accuracy_score(Y, gbc_predict)  \n",
    "gbc_precision = metrics.precision_score(Y, gbc_predict, pos_label=1)\n",
    "gbc_recall = metrics.recall_score(Y, gbc_predict, pos_label=1)  \n",
    "gbc_f1 = metrics.f1_score(Y, gbc_predict, pos_label=1)\n",
    "gbc_auroc = metrics.roc_auc_score(Y, gbc_predict_proba[1])\n",
    "gbc_aurpc = metrics.average_precision_score(Y, gbc_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.88\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gnb_predict = cross_val_predict(gnb, X, Y, cv = kFold)\n",
    "gnb_predict_proba = pd.DataFrame(cross_val_predict(gnb, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "gnb_accuracy = metrics.accuracy_score(Y, gnb_predict)  \n",
    "gnb_precision = metrics.precision_score(Y, gnb_predict, pos_label=1)\n",
    "gnb_recall = metrics.recall_score(Y, gnb_predict, pos_label=1)  \n",
    "gnb_f1 = metrics.f1_score(Y, gnb_predict, pos_label=1)\n",
    "gnb_auroc = metrics.roc_auc_score(Y, gnb_predict_proba[1])\n",
    "gnb_aurpc = metrics.average_precision_score(Y, gnb_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstart = time.time()\\ngpc_predict = cross_val_predict(gpc, X, Y, cv = kFold)\\ngpc_predict_proba = pd.DataFrame(cross_val_predict(gpc, X, Y, cv = kFold, method='predict_proba'))\\nend = time.time()\\n\\n# Store metrics\\ngpc_accuracy = metrics.accuracy_score(Y, gpc_predict)  \\ngpc_precision = metrics.precision_score(Y, gpc_predict, pos_label=1)\\ngpc_recall = metrics.recall_score(Y, gpc_predict, pos_label=1)  \\ngpc_f1 = metrics.f1_score(Y, gpc_predict, pos_label=1)\\ngpc_auroc = metrics.roc_auc_score(Y, gpc_predict_proba[1])\\ngpc_aurpc = metrics.average_precision_score(Y, gpc_predict, pos_label=1)\\n\\nprint('Time: ', round(end - start, 2))\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "start = time.time()\n",
    "gpc_predict = cross_val_predict(gpc, X, Y, cv = kFold)\n",
    "gpc_predict_proba = pd.DataFrame(cross_val_predict(gpc, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "gpc_accuracy = metrics.accuracy_score(Y, gpc_predict)  \n",
    "gpc_precision = metrics.precision_score(Y, gpc_predict, pos_label=1)\n",
    "gpc_recall = metrics.recall_score(Y, gpc_predict, pos_label=1)  \n",
    "gpc_f1 = metrics.f1_score(Y, gpc_predict, pos_label=1)\n",
    "gpc_auroc = metrics.roc_auc_score(Y, gpc_predict_proba[1])\n",
    "gpc_aurpc = metrics.average_precision_score(Y, gpc_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  3.57\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "knc_predict = cross_val_predict(knc, X, Y, cv = kFold)\n",
    "knc_predict_proba = pd.DataFrame(cross_val_predict(knc, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "knc_accuracy = metrics.accuracy_score(Y, knc_predict)  \n",
    "knc_precision = metrics.precision_score(Y, knc_predict, pos_label=1)\n",
    "knc_recall = metrics.recall_score(Y, knc_predict, pos_label=1)  \n",
    "knc_f1 = metrics.f1_score(Y, knc_predict, pos_label=1)\n",
    "knc_auroc = metrics.roc_auc_score(Y, knc_predict_proba[1])\n",
    "knc_aurpc = metrics.average_precision_score(Y, knc_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  63.08\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mlp_predict = cross_val_predict(mlp, X, Y, cv = kFold)\n",
    "mlp_predict_proba = pd.DataFrame(cross_val_predict(mlp, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "mlp_accuracy = metrics.accuracy_score(Y, mlp_predict)  \n",
    "mlp_precision = metrics.precision_score(Y, mlp_predict, pos_label=1)\n",
    "mlp_recall = metrics.recall_score(Y, mlp_predict, pos_label=1)  \n",
    "mlp_f1 = metrics.f1_score(Y, mlp_predict, pos_label=1)\n",
    "mlp_auroc = metrics.roc_auc_score(Y, mlp_predict_proba[1])\n",
    "mlp_aurpc = metrics.average_precision_score(Y, mlp_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  12.09\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "rfc_predict = cross_val_predict(rfc, X, Y, cv = kFold)\n",
    "rfc_predict_proba = pd.DataFrame(cross_val_predict(rfc, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "rfc_accuracy = metrics.accuracy_score(Y, rfc_predict)  \n",
    "rfc_precision = metrics.precision_score(Y, rfc_predict, pos_label=1)\n",
    "rfc_recall = metrics.recall_score(Y, rfc_predict, pos_label=1)  \n",
    "rfc_f1 = metrics.f1_score(Y, rfc_predict, pos_label=1)\n",
    "rfc_auroc = metrics.roc_auc_score(Y, rfc_predict_proba[1])\n",
    "rfc_aurpc = metrics.average_precision_score(Y, rfc_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstart = time.time()\\nsvc_predict = cross_val_predict(svc, X, Y, cv = kFold)\\nsvc_predict_proba = pd.DataFrame(cross_val_predict(svc, X, Y, cv = kFold, method='predict_proba'))\\nend = time.time()\\n\\n# Store metrics\\nsvc_accuracy = metrics.accuracy_score(Y, svc_predict)  \\nsvc_precision = metrics.precision_score(Y, svc_predict, pos_label=1)\\nsvc_recall = metrics.recall_score(Y, svc_predict, pos_label=1)  \\nsvc_f1 = metrics.f1_score(Y, svc_predict, pos_label=1)\\nsvc_auroc = metrics.roc_auc_score(Y, svc_predict_proba[1])\\nsvc_aurpc = metrics.average_precision_score(Y, svc_predict, pos_label=1)\\n\\nprint('Time: ', round(end - start, 2))\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "start = time.time()\n",
    "svc_predict = cross_val_predict(svc, X, Y, cv = kFold)\n",
    "svc_predict_proba = pd.DataFrame(cross_val_predict(svc, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "svc_accuracy = metrics.accuracy_score(Y, svc_predict)  \n",
    "svc_precision = metrics.precision_score(Y, svc_predict, pos_label=1)\n",
    "svc_recall = metrics.recall_score(Y, svc_predict, pos_label=1)  \n",
    "svc_f1 = metrics.f1_score(Y, svc_predict, pos_label=1)\n",
    "svc_auroc = metrics.roc_auc_score(Y, svc_predict_proba[1])\n",
    "svc_aurpc = metrics.average_precision_score(Y, svc_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  91.93\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "xgb_predict = cross_val_predict(xgb, X, Y, cv = kFold)\n",
    "xgb_predict_proba = pd.DataFrame(cross_val_predict(xgb, X, Y, cv = kFold, method='predict_proba'))\n",
    "end = time.time()\n",
    "\n",
    "# Store metrics\n",
    "xgb_accuracy = metrics.accuracy_score(Y, xgb_predict)  \n",
    "xgb_precision = metrics.precision_score(Y, xgb_predict, pos_label=1)\n",
    "xgb_recall = metrics.recall_score(Y, xgb_predict, pos_label=1)  \n",
    "xgb_f1 = metrics.f1_score(Y, xgb_predict, pos_label=1)\n",
    "xgb_auroc = metrics.roc_auc_score(Y, xgb_predict_proba[1])\n",
    "xgb_aurpc = metrics.average_precision_score(Y, xgb_predict, pos_label=1)\n",
    "\n",
    "print('Time: ', round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {\n",
    "    'ADABoost': abc_predict,\n",
    "    'ExtraTrees': etc_predict,\n",
    "    'RandomForest': rfc_predict,\n",
    "    'GradientBoosting': gbc_predict,\n",
    "    'XGBoost': xgb_predict,\n",
    "    'DecisionTree': dtc_predict,\n",
    "    'MultiLayerPerceptron': mlp_predict,\n",
    "    'KNeighbors': knc_predict,\n",
    "    'NaiveBayes': gnb_predict\n",
    "} \n",
    "\n",
    "predictions = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store metrics\n",
    "predictions['Aggregate'] = predictions.mean(axis=1)\n",
    "aggregate_auroc = metrics.roc_auc_score(Y, predictions['Aggregate'])\n",
    "\n",
    "predictions['Aggregate'] = round(predictions['Aggregate']).astype(int)\n",
    "aggregate_accuracy = metrics.accuracy_score(Y, predictions['Aggregate'])  \n",
    "aggregate_precision = metrics.precision_score(Y, predictions['Aggregate'], pos_label=1)\n",
    "aggregate_recall = metrics.recall_score(Y, predictions['Aggregate'], pos_label=1)  \n",
    "aggregate_f1 = metrics.f1_score(Y, predictions['Aggregate'], pos_label=1)\n",
    "aggregate_aurpc = metrics.average_precision_score(Y, predictions['Aggregate'], pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AURPC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>ADA Boost</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Aggregate</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>XG Boost</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.999948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Multi Layer Perceptron</td>\n",
       "      <td>0.949115</td>\n",
       "      <td>0.970286</td>\n",
       "      <td>0.747446</td>\n",
       "      <td>0.962830</td>\n",
       "      <td>0.965675</td>\n",
       "      <td>0.974941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.847676</td>\n",
       "      <td>0.916041</td>\n",
       "      <td>0.656407</td>\n",
       "      <td>0.863404</td>\n",
       "      <td>0.863691</td>\n",
       "      <td>0.975147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>K Neighbors</td>\n",
       "      <td>0.836283</td>\n",
       "      <td>0.909867</td>\n",
       "      <td>0.567990</td>\n",
       "      <td>0.856830</td>\n",
       "      <td>0.856976</td>\n",
       "      <td>0.969717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Accuracy        F1     AUROC     AURPC  Precision  \\\n",
       "             Extra Trees  0.999934  0.999961  1.000000  0.999966   0.999974   \n",
       "       Gradient Boosting  0.999934  0.999961  1.000000  0.999944   0.999948   \n",
       "           Decision Tree  0.999934  0.999961  0.999825  0.999944   0.999948   \n",
       "               ADA Boost  0.999912  0.999948  0.999983  0.999941   0.999948   \n",
       "               Aggregate  0.999912  0.999948  0.999986  0.999941   0.999948   \n",
       "           Random Forest  0.999890  0.999935  0.999970  0.999915   0.999922   \n",
       "                XG Boost  0.999780  0.999871  0.999911  0.999786   0.999793   \n",
       "  Multi Layer Perceptron  0.949115  0.970286  0.747446  0.962830   0.965675   \n",
       "             Naive Bayes  0.847676  0.916041  0.656407  0.863404   0.863691   \n",
       "             K Neighbors  0.836283  0.909867  0.567990  0.856830   0.856976   \n",
       "\n",
       "    Recall  \n",
       "  0.999948  \n",
       "  0.999974  \n",
       "  0.999974  \n",
       "  0.999948  \n",
       "  0.999948  \n",
       "  0.999948  \n",
       "  0.999948  \n",
       "  0.974941  \n",
       "  0.975147  \n",
       "  0.969717  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['ADA Boost', 'Extra Trees', 'Random Forest', 'Gradient Boosting', 'XG Boost', 'Decision Tree',\n",
    "              'Multi Layer Perceptron', 'K Neighbors', 'Naive Bayes', 'Aggregate'],\n",
    "    'Accuracy' : [abc_accuracy, etc_accuracy, rfc_accuracy, gbc_accuracy, xgb_accuracy, dtc_accuracy,\n",
    "                  mlp_accuracy, knc_accuracy, gnb_accuracy, aggregate_accuracy],\n",
    "    'F1' : [abc_f1, etc_f1, rfc_f1, gbc_f1, xgb_f1, dtc_f1, mlp_f1, knc_f1, gnb_f1, aggregate_f1],\n",
    "    'AUROC' : [abc_auroc, etc_auroc, rfc_auroc, gbc_auroc, xgb_auroc, dtc_auroc, mlp_auroc, knc_auroc, \n",
    "               gnb_auroc, aggregate_auroc],\n",
    "    'AURPC' : [abc_aurpc, etc_aurpc, rfc_aurpc, gbc_aurpc, xgb_aurpc, dtc_aurpc, mlp_aurpc, knc_aurpc,\n",
    "               gnb_aurpc, aggregate_aurpc],\n",
    "    'Precision': [abc_precision, etc_precision, rfc_precision, gbc_precision, xgb_precision, dtc_precision, mlp_precision, \n",
    "                  knc_precision, gnb_precision, aggregate_precision],\n",
    "    'Recall' : [abc_recall, etc_recall, rfc_recall, gbc_recall, xgb_recall, dtc_recall, mlp_recall, knc_recall,\n",
    "                gnb_recall, aggregate_recall]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models = models.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "blankIndex=[''] * len(models)\n",
    "models.index=blankIndex\n",
    "models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
