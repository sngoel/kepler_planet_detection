{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import warnings\n",
    "\n",
    "import time as time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Read out 100 rows rather than the default value. \n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Not prinitng the warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting the working path for data input and result outputs\n",
    "os.chdir('D:\\\\Spring 2019\\\\DS 440\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: \n",
      "(45377, 26)\n"
     ]
    }
   ],
   "source": [
    "#filenames = glob('D:\\Spring 2019\\DS 440\\Data\\kplr_dr25_inj*.csv')\n",
    "#df = pd.concat([pd.read_csv(f) for f in filenames], ignore_index = True)\n",
    "\n",
    "# Problem 2\n",
    "#df = pd.read_csv('kplr_dr25_inj1_plti.csv', header = 0)\n",
    "\n",
    "# Problem 2\n",
    "df = pd.read_csv('kplr_dr25_inj1_tces.csv', header = 0)\n",
    "\n",
    "print('Size: ')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TCE_ID', 'KIC', 'Disp', 'Score', 'period', 'epoch', 'NTL', 'SS', 'CO',\n",
       "       'EM', 'Expected_MES', 'MES', 'NTran', 'depth', 'duration', 'Rp', 'Rs',\n",
       "       'Ts', 'logg', 'a', 'Rp/Rs', 'a/Rs', 'impact', 'SNR_DV', 'Sp',\n",
       "       'Fit_Prov'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['TCE_ID', 'KIC', 'Disp', 'Score', 'period', 'epoch', 'NTL', 'SS', \n",
    "        'CO', 'EM', 'Expected_MES', 'MES', 'NTran', 'depth', 'duration', 'Rp',\n",
    "        'Rs', 'Ts', 'logg', 'a', 'Rp/Rs', 'a/Rs', 'impact', 'SNR_DV', 'Sp',\n",
    "        'Fit_Prov']\n",
    "df = df[cols]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntemp_df = df.iloc[:, 0:15]\\ndf_drop = temp_df[temp_df.isnull().any(axis=1)]\\ntemp_df = temp_df.drop(df_drop.index.values)\\nprint(temp_df.shape)\\n\\nX = temp_df.iloc[:, 1:14]\\nY = temp_df.iloc[:, 14]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "temp_df = df.iloc[:, 0:15]\n",
    "df_drop = temp_df[temp_df.isnull().any(axis=1)]\n",
    "temp_df = temp_df.drop(df_drop.index.values)\n",
    "print(temp_df.shape)\n",
    "\n",
    "X = temp_df.iloc[:, 1:14]\n",
    "Y = temp_df.iloc[:, 14]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Disp'] = df['Disp'].replace('PC', 1)\n",
    "df['Disp'] = df['Disp'].replace('FP', 0)\n",
    "\n",
    "X = df.iloc[:, 6:25]\n",
    "Y = df.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier() #n_estimators\n",
    "etc = ExtraTreesClassifier() #n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "rfc = RandomForestClassifier() #n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "gbc = GradientBoostingClassifier() #n_estimators, max_depth, min_samples_split, min_samples_leaf\n",
    "\n",
    "xgb = XGBClassifier() #n_estimators, max_depth\n",
    "svc = SVC() #C, kernel, gamma, degree\n",
    "dtc = DecisionTreeClassifier() #max_depth, min_samples_split, min_samples_leaf\n",
    "mlp = MLPClassifier()\n",
    "knc = KNeighborsClassifier() #n_neighbors, p\n",
    "gpc = GaussianProcessClassifier()\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 350, num = 5)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(start = 2, stop = 30, num = 10)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [0.10, 0.25, 0.50, 1, 2, 4]\n",
    "\n",
    "# Minimum number of neighbors required for each node\n",
    "n_neighbors = [int(x) for x in np.linspace(start = 3, stop = 30, num = 10)]\n",
    "\n",
    "# Minimum Power parameter required for the Minkowski metric\n",
    "p = [float(x) for x in np.linspace(start = 1, stop = 5, num = 10)]\n",
    "\n",
    "# Minimum penalty parameter C of the error term\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Type of kernel algorithm\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "\n",
    "# Minimum kernel coefficient\n",
    "gamma = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Degree of the polynomial kernel function\n",
    "degree = [0, 1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Classifier\n",
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 27.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 20.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Classifier\n",
      "Fitting 10 folds for each of 300 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 236 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1436 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2336 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3000 out of 3000 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees Classifier\n",
      "Fitting 10 folds for each of 1500 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 450 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 800 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1250 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1800 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3200 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4050 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5000 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6050 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8450 tasks      | elapsed: 49.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9800 tasks      | elapsed: 58.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11250 tasks      | elapsed: 69.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12800 tasks      | elapsed: 81.7min\n",
      "[Parallel(n_jobs=-1)]: Done 14450 tasks      | elapsed: 94.8min\n",
      "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed: 101.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier\n",
      "Fitting 10 folds for each of 1500 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 42.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 56.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 77.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 108.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 132.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 160.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 192.9min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 230.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 271.0min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 316.5min\n",
      "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed: 341.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Create the param grid\n",
    "param_grid = dict(n_neighbors = n_neighbors,\n",
    "                  p = p)\n",
    "\n",
    "print('KNeighbors Classifier')\n",
    "knc_grid_search = GridSearchCV(knc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "knc_grid_result = knc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = n_estimators)\n",
    "\n",
    "print('AdaBoost Classifier')\n",
    "abc_grid_search = GridSearchCV(abc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "abc_grid_result = abc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = n_estimators,\n",
    "                  max_depth = max_depth)\n",
    "\n",
    "print('XGBoost Classifier')\n",
    "xgb_grid_search = GridSearchCV(xgb, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "xgb_grid_result = xgb_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(max_depth = max_depth,\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "print('DecisionTree Classifier')\n",
    "dtc_grid_search = GridSearchCV(dtc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "dtc_grid_result = dtc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "# Updating the param grid\n",
    "param_grid = dict(n_estimators = n_estimators,\n",
    "                  max_depth = max_depth,\n",
    "                  min_samples_split = min_samples_split,\n",
    "                  min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "print('ExtraTrees Classifier')\n",
    "etc_grid_search = GridSearchCV(etc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "etc_grid_result = etc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "print('RandomForest Classifier')\n",
    "rfc_grid_search = GridSearchCV(rfc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "rfc_grid_result = rfc_grid_search.fit(X, Y)\n",
    "\n",
    "dill.dump_session('parameter_testing.db')\n",
    "\n",
    "#print('GradientBoosting Classifier')\n",
    "#gbc_grid_search = GridSearchCV(gbc, param_grid, scoring = 'accuracy', n_jobs = -1, cv = kfold, verbose = 1)\n",
    "#gbc_grid_result = gbc_grid_search.fit(X, Y)\n",
    "\n",
    "#dill.dump_session('parameter_testing.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Classifier:\n",
      "Best: 0.852833 using {'n_neighbors': 24, 'p': 1.0}\n",
      "\n",
      "AdaBoost Classifier:\n",
      "Best: 0.999912 using {'n_estimators': 10}\n",
      "\n",
      "XGBoost Classifier:\n",
      "Best: 0.999956 using {'max_depth': 5, 'n_estimators': 10}\n",
      "\n",
      "DecisionTree Classifier:\n",
      "Best: 0.999956 using {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "\n",
      "ExtraTrees Classifier:\n",
      "Best: 0.999978 using {'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 4, 'n_estimators': 10}\n",
      "\n",
      "RandomForest Classifier:\n",
      "Best: 0.999956 using {'max_depth': 11, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 180}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results\n",
    "print('KNeighbors Classifier:')\n",
    "print(\"Best: %f using %s\" % (knc_grid_result.best_score_, knc_grid_result.best_params_))\n",
    "\n",
    "print('\\nAdaBoost Classifier:')\n",
    "print(\"Best: %f using %s\" % (abc_grid_result.best_score_, abc_grid_result.best_params_))\n",
    "\n",
    "print('\\nXGBoost Classifier:')\n",
    "print(\"Best: %f using %s\" % (xgb_grid_result.best_score_, xgb_grid_result.best_params_))\n",
    "\n",
    "print('\\nDecisionTree Classifier:')\n",
    "print(\"Best: %f using %s\" % (dtc_grid_result.best_score_, dtc_grid_result.best_params_))\n",
    "\n",
    "print('\\nExtraTrees Classifier:')\n",
    "print(\"Best: %f using %s\" % (etc_grid_result.best_score_, etc_grid_result.best_params_))\n",
    "\n",
    "print('\\nRandomForest Classifier:')\n",
    "print(\"Best: %f using %s\" % (rfc_grid_result.best_score_, rfc_grid_result.best_params_))\n",
    "\n",
    "#print('\\nGradientBoosting Classifier:')\n",
    "#print(\"Best: %f using %s\" % (gbc_grid_result.best_score_, gbc_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmeans = _grid_result.cv_results_[\\'mean_test_score\\']\\nstds = _grid_result.cv_results_[\\'std_test_score\\']\\nparams = _grid_result.cv_results_[\\'params\\']\\nfor mean, stdev, param in zip(means, stds, params):\\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "means = _grid_result.cv_results_['mean_test_score']\n",
    "stds = _grid_result.cv_results_['std_test_score']\n",
    "params = _grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
